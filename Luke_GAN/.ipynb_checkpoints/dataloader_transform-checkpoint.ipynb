{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4eb057d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31740\\1449710636.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch \n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b6bee",
   "metadata": {},
   "source": [
    "Documentation [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) plus an example of when there is too much data to fit into ram. In this case, the __getitem__ method uses indx to find the right file, i.e., each image is stored in a separate .npy save file. Probably the best option is to have the file structure:  \n",
    "\n",
    "-------------\n",
    "scripts  \n",
    "- data    \n",
    "    - sdo  \n",
    "        - obsid \n",
    "            - image .npy files \n",
    "    - iris\n",
    "        - obsid\n",
    "            - image .npy files \n",
    "-------------\n",
    "\n",
    "\n",
    "do this and make two directories, one for IRIS and the other for AIA images. Also if they are slightly aligned and not just random, store the images in either sdo or iris directories with the same index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29837c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  19\n",
      "Train obsid:  15\n",
      "Test obsid:  4\n"
     ]
    }
   ],
   "source": [
    "os.chdir('D:/Example CR IRIS/GAN_data')\n",
    "obs_list = os.listdir('iris/')\n",
    "print(\"Total: \", len(obs_list))\n",
    "x_train_obs ,x_test_obs = train_test_split(obs_list,test_size=0.2)\n",
    "print(\"Train obsid: \",len(x_train_obs))\n",
    "print(\"Test obsid: \",len(x_test_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10a9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define personal dataset\n",
    "#from torch.utils.dataset import Dataset,Dataloader\n",
    "\n",
    "class AIAIRISdataset(Dataset):\n",
    "    def __init__(self,obs,aia_root_dir,iris_root_dir,aia_transform = None, iris_transform = None):\n",
    "        # Load data. If there is too much data to keep in ram then we will just define file paths\n",
    "        # to individual images and load them one at a time, afterward we can use multiple workers to parallelize \n",
    "        # the feeding in of data to the models. \n",
    "        super(AIAIRISdataset, self).__init__() \n",
    "        \n",
    "        print(aia_transform)\n",
    "\n",
    "                \n",
    "        aia_arr = []\n",
    "        iris_arr = []\n",
    "        for i in obs:\n",
    "            print(i)\n",
    "            root_dir = aia_root_dir + '/' + i\n",
    "            aia_bands = os.listdir(root_dir)\n",
    "            \n",
    "            for j in aia_bands:\n",
    "                aia_file_dir = root_dir + '/' + j\n",
    "                #print(aia_file_dir)\n",
    "                aia_files = os.listdir(aia_file_dir)\n",
    "                #aia_arr = []\n",
    "                \n",
    "                for aia_file in aia_files:\n",
    "                    ar = np.load(aia_file_dir + '/' + aia_file)\n",
    "                    data = ar.astype(np.float32)\n",
    "                    #ar = torch.from_numpy(data)\n",
    "                    \n",
    "                    #ar = data.byteswap().newbyteorder()\n",
    "                    \n",
    "                    aia_arr.append(data)\n",
    "                 \n",
    "                #self.aia_test_data = np.array(aia_arr)\n",
    "                #self.aia_transform = aia_transform\n",
    "            \n",
    "            \n",
    "            \n",
    "            root_dir = iris_root_dir + '/' + i\n",
    "            iris_bands = os.listdir(root_dir)\n",
    "            for j in iris_bands:\n",
    "                iris_file_dir = root_dir + '/' +j\n",
    "                iris_files = os.listdir(iris_file_dir)\n",
    "                #iris_arr = []\n",
    "                for iris_file in iris_files:\n",
    "                    ar = np.load(iris_file_dir + '/' + iris_file)\n",
    "                    data = ar.astype(np.float32)\n",
    "                    \n",
    "                    #ar = data.byteswap().newbyteorder()\n",
    "                    \n",
    "                    #ar = torch.from_numpy(data)\n",
    "                    iris_arr.append(data)\n",
    "                    \n",
    "                #self.iris_test_data = np.array(iris_arr)\n",
    "                #self.iris_transform = iris_transform\n",
    "                \n",
    "        self.aia_test_data = np.array(aia_arr)\n",
    "        print(len(self.aia_test_data))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.aia_transform = aia_transform  \n",
    "        \n",
    "        self.iris_test_data = np.array(iris_arr)\n",
    "        self.iris_transform = iris_transform\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # So the loader knows when an epoch is reached\n",
    "        return self.iris_test_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Select single images and turn into PyTorch tensors\n",
    "        aia_im = torch.from_numpy(self.aia_test_data[index])\n",
    "        iris_im = torch.from_numpy(self.iris_test_data[index])\n",
    "        #aia_im.aia_im.to(device)\n",
    "        #iris_im.iris_im.to(device)\n",
    "        \n",
    "        if self.aia_transform:\n",
    "            aia_im = self.aia_transform(aia_im)\n",
    "            \n",
    "        if self.iris_transform:\n",
    "            iris_im = self.iris_transform(iris_im)\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        return aia_im, iris_im "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09b55af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aia_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((512,512)),\n",
    "    transforms.RandomRotation(90),\n",
    "    #transforms.RandomCrop(224),\n",
    "    transforms.ToTensor()\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d4b13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((1024,1024)),\n",
    "    transforms.RandomRotation(90),\n",
    "    #transforms.RandomCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8375ae36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToPILImage()\n",
      "    Resize(size=(512, 512), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomRotation(degrees=(-90, 90), resample=False, expand=False)\n",
      "    ToTensor()\n",
      ")\n",
      "20180830_135414_3620110404\n",
      "20160212_122145_3690113103\n",
      "20131208_230830_3880262154\n",
      "20160212_135911_3690113103\n",
      "20220923_103842_3690133103\n",
      "20131206_023345_3800260154\n",
      "20131119_171530_3893012103\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AIAIRISdataset(x_train_obs,'sdo','iris',aia_transform,iris_transform) # create an instance of the dataset\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0) # turn into a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90099e2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_dataset = AIAIRISdataset(x_test_obs,'sdo','iris',aia_transform) # create an instance of the dataset\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, shuffle=True, num_workers=0) # turn into a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb8d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = next(iter(train_data_loader))\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2918d05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_test, y_test = next(iter(test_data_loader))\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4, 2, figsize=(10, 15))\n",
    "indices = torch.randperm(len(x_train))[:4]\n",
    "print(indices)\n",
    "for i, samples in enumerate(zip(x_train[indices], y_train[indices])):\n",
    "    aia = (((samples[0][0]).numpy()).astype(np.uint8))\n",
    "    iris = (((samples[1][0]).numpy()).astype(np.uint8))\n",
    "    ax[i, 0].imshow(aia)\n",
    "    ax[i, 1].imshow(iris)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76152c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
